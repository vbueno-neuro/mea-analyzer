{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab73b9d0-dff5-4ad5-b16c-4f4abf3f159f",
   "metadata": {},
   "source": [
    "# MEA analyzer pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac6432-738d-4bd2-81a8-3150c1d780c1",
   "metadata": {},
   "source": [
    "## Part 1: Setup & Initialization\n",
    "\n",
    "### Project root setup, core libraries and project modules - Please read carefully the text instructions\n",
    "\n",
    "This part should be unchanged by users except maybe paths. Its job is to guarantee:\n",
    "\n",
    "- Correct project root\n",
    "- Correct imports\n",
    "- Reproducibility\n",
    "- No silent path bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5960d4-d867-4aea-8050-aae9fa8163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROJECT ROOT SETUP\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "HERE = Path.cwd().resolve()\n",
    "\n",
    "# Find project root by locating \"src\" folder\n",
    "PROJECT_ROOT = next(\n",
    "    p for p in [HERE, *HERE.parents]\n",
    "    if (p / \"src\").exists()\n",
    ")\n",
    "\n",
    "print(\"Notebook directory:\", HERE)\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"src exists?\", (PROJECT_ROOT / \"src\").exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526bace-28f3-4d00-80cb-f452f506f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CORE LIBRARIES\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # optional, used later for aesthetics\n",
    "\n",
    "# Global plotting defaults\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7c8ab-b9b5-4c75-a85b-d655e7b80d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROJECT MODULES\n",
    "# =========================\n",
    "\n",
    "# Configuration\n",
    "from config_handler import ConfigHandler\n",
    "\n",
    "# Data ingestion & organization\n",
    "from data_loader import load_mea_csv_well_averages\n",
    "from data_organizer import DataOrganizer\n",
    "\n",
    "# QC & preprocessing\n",
    "from qc.outliers import (\n",
    "    OutlierSpec,\n",
    "    flag_outliers,\n",
    "    get_outliers_table,\n",
    "    apply_outlier_filter\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "from analysis.normalization import baseline_normalize\n",
    "\n",
    "# Visualization\n",
    "from visualization.plot_plate_layout import plot_plate_layout\n",
    "from visualization.timecourse import plot_metric_timecourse\n",
    "\n",
    "# Export\n",
    "from io.table_export import export_metric_tables_wide\n",
    "\n",
    "print(\"All project modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27b63b-32aa-49e5-aa06-1132346005fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROJECT PATHS\n",
    "# =========================\n",
    "\n",
    "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"figures\"\n",
    "\n",
    "# Optional processed data directory\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Create directories if missing\n",
    "for d in [OUTPUTS_DIR, FIGURES_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Config dir:\", CONFIG_DIR)\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "print(\"Outputs dir:\", OUTPUTS_DIR)\n",
    "print(\"Figures dir:\", FIGURES_DIR)\n",
    "print(\"Processed dir:\", PROCESSED_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca9945-e181-4a83-8358-2f29c73766d6",
   "metadata": {},
   "source": [
    "### The next two cells should be edited by users to choose plate configuration and global analysis switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a50f2-3e96-4cad-ab93-473ac79b5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD CONFIGURATIONS\n",
    "# =========================\n",
    "\n",
    "# Metrics configuration\n",
    "config_handler = ConfigHandler(PROJECT_ROOT)\n",
    "metrics_config = config_handler.load_metrics_config()\n",
    "\n",
    "# Experiment configuration (USER EDITS THIS)\n",
    "CONFIG_PATH = CONFIG_DIR / \"MY_EXPERIMENT.yaml\" # <-- CHANGE THIS TO YOUR PLATE CONFIGURATION FILE\n",
    "\n",
    "if not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Experiment config not found: {CONFIG_PATH}\")\n",
    "\n",
    "print(\"Using experiment config:\", CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd2083-419b-4a55-b89f-82784a219784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# USER ANALYSIS OPTIONS\n",
    "# =========================\n",
    "\n",
    "# Export tables\n",
    "EXPORT_MODE = \"both\"          # <-- CHANGE THIS TO YOUR CHOICE \"raw\", \"normalized\", or \"both\"\n",
    "\n",
    "# Outlier handling\n",
    "OUTLIER_METHOD = \"zscore\"     # <-- CHANGE THIS TO YOUR CHOICE \"zscore\", \"iqr\", \"mad\"\n",
    "\n",
    "OUTLIER_Z = 3.0               # <-- CHANGE THIS TO YOUR CHOICE (Z score value to detect outliers)\n",
    "\n",
    "REMOVE_OUTLIERS = True        # <-- CHANGE THIS TO YOUR CHOICE \"True\" = Remove flagged outliers || \"False\" = Keep flagged outliers\n",
    "\n",
    "# Normalization\n",
    "NORMALIZE_TO_BASELINE = True  # <-- CHANGE THIS TO YOUR CHOICE \"True\" = Plot after outlier removal is normalized to baseline || \"False\" = Plot after outlier removal uses raw values\n",
    "\n",
    "BASELINE_PREFIX = \"0_\"        # baseline files start with \"0_\" (DO NOT CHANGE)\n",
    "\n",
    "print(\"EXPORT_MODE:\", EXPORT_MODE)\n",
    "print(\"OUTLIER_METHOD:\", OUTLIER_METHOD)\n",
    "print(\"REMOVE_OUTLIERS:\", REMOVE_OUTLIERS)\n",
    "print(\"NORMALIZE_TO_BASELINE:\", NORMALIZE_TO_BASELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b4b31-b21c-4e1a-b113-1818cea6c459",
   "metadata": {},
   "source": [
    "## Part 2: Validation of experiment details & Configuration of plate and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211325f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8903b6-eda0-4525-8e7c-82f4461f88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD EXPERIMENT CONFIG\n",
    "# =========================\n",
    "import yaml\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    experiment_config = yaml.safe_load(f)\n",
    "\n",
    "experiment_info = experiment_config.get(\"experiment\", {})\n",
    "conditions = experiment_config.get(\"conditions\", {})\n",
    "time_points = experiment_config.get(\"time_points\", [])\n",
    "\n",
    "print(\"Plate ID:\", experiment_info.get(\"plate_id\", \"UNKNOWN\"))\n",
    "print(\"Data directory:\", experiment_info.get(\"data_dir\", \"UNKNOWN\"))\n",
    "print(\"Number of conditions:\", len(conditions))\n",
    "print(\"Conditions:\")\n",
    "for name, info in conditions.items():\n",
    "    print(f\"  - {name}: {len(info['wells'])} wells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2d984-95ab-4279-8fa7-0f5d11072b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# VALIDATE WELL ASSIGNMENTS\n",
    "# =========================\n",
    "\n",
    "VALID_ROWS = {\"A\", \"B\", \"C\", \"D\"}\n",
    "VALID_COLS = {\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"}\n",
    "\n",
    "def is_valid_well(well):\n",
    "    return (\n",
    "        len(well) in (2, 3)\n",
    "        and well[0] in VALID_ROWS\n",
    "        and well[1:] in VALID_COLS\n",
    "    )\n",
    "\n",
    "all_wells = []\n",
    "errors = []\n",
    "\n",
    "for cond, info in conditions.items():\n",
    "    for w in info[\"wells\"]:\n",
    "        if not is_valid_well(w):\n",
    "            errors.append(f\"Invalid well name: {w} (condition: {cond})\")\n",
    "        all_wells.append(w)\n",
    "\n",
    "# Check duplicates\n",
    "from collections import Counter\n",
    "counts = Counter(all_wells)\n",
    "duplicates = [w for w, c in counts.items() if c > 1]\n",
    "\n",
    "if errors:\n",
    "    print(\"❌ WELL FORMAT ERRORS:\")\n",
    "    for e in errors:\n",
    "        print(\"  \", e)\n",
    "\n",
    "if duplicates:\n",
    "    print(\"❌ DUPLICATE WELL ASSIGNMENTS:\")\n",
    "    for w in duplicates:\n",
    "        print(\"  \", w)\n",
    "\n",
    "if not errors and not duplicates:\n",
    "    print(\"✓ Well assignments validated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f8033-5a2f-4be8-bb79-e12fa8f005df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PLATE LAYOUT VISUALIZATION\n",
    "# =========================\n",
    "\n",
    "fig = plot_plate_layout(CONFIG_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5082ad-e902-4a52-a36e-4c791bd40a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TIME POINT LABELS\n",
    "# =========================\n",
    "\n",
    "if not time_points:\n",
    "    print(\"No time points defined in config.\")\n",
    "    timepoint_labels = {}\n",
    "else:\n",
    "    timepoint_labels = {tp[\"index\"]: tp[\"label\"] for tp in time_points}\n",
    "    print(\"Time point labels:\")\n",
    "    for k, v in timepoint_labels.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff93fe7-4487-4759-bf93-64479f49bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# USER CONFIRMATION\n",
    "# =========================\n",
    "\n",
    "print(\"\\nQC CHECKLIST:\")\n",
    "print(\"✓ Plate layout visually confirmed\")\n",
    "print(\"✓ Conditions and wells verified\")\n",
    "print(\"✓ Time points verified\")\n",
    "\n",
    "print(\"\\nIf anything above is wrong:\")\n",
    "print(\"  → Stop here\")\n",
    "print(\"  → Fix the experiment config\")\n",
    "print(\"  → Restart the notebook\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bd8f9-ad6b-4f24-9000-e20f8bd53c38",
   "metadata": {},
   "source": [
    "## Part 3: Data loading & Master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1efd77-eb3c-44d4-91a8-9aa6a62fcc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOCATE RAW DATA FILES\n",
    "# =========================\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / experiment_info[\"data_dir\"]\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Data directory not found: {DATA_PATH}\")\n",
    "\n",
    "# Collect CSV files\n",
    "csv_files = sorted(\n",
    "    DATA_PATH.glob(\"*.csv\"),\n",
    "    key=lambda p: int(p.name.split(\"_\")[0])  # assumes 0_, 1_, 2_, ...\n",
    ")\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for f in csv_files:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "# Baseline check\n",
    "if not csv_files or not csv_files[0].name.startswith(BASELINE_PREFIX):\n",
    "    raise ValueError(\n",
    "        f\"First file must be baseline and start with '{BASELINE_PREFIX}'. \"\n",
    "        f\"Found: {csv_files[0].name if csv_files else 'NONE'}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03a748-7088-4948-bafb-e713a2a4fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# INITIALIZE DATA ORGANIZER\n",
    "# =========================\n",
    "\n",
    "organizer = DataOrganizer(\n",
    "    experiment_config_path=CONFIG_PATH,\n",
    "    config_handler=config_handler\n",
    ")\n",
    "\n",
    "print(\"DataOrganizer initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de1769-7567-41f1-b76d-068aa13859b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BUILD MASTER DATAFRAME\n",
    "# =========================\n",
    "\n",
    "master_df = organizer.create_master_dataframe(\n",
    "    data_loader_func=load_mea_csv_well_averages,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nMaster dataframe created.\")\n",
    "print(\"Shape:\", master_df.shape)\n",
    "print(\"Columns:\", list(master_df.columns))\n",
    "\n",
    "# Expected columns: plate_id | time_point | well | condition | condition_color | metric | metric_type | value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de3f29-d429-42ed-8fe8-a08699bbcdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SELECT METRICS FOR PIPELINE (AUTOMATIC)\n",
    "# =========================\n",
    "\n",
    "AVAILABLE_METRICS = sorted(\n",
    "    set(master_df[\"metric\"])\n",
    "    & set(config_handler.get_all_metrics())\n",
    ")\n",
    "\n",
    "print(f\"Metrics available for analysis ({len(AVAILABLE_METRICS)}):\")\n",
    "for m in AVAILABLE_METRICS:\n",
    "    print(\" -\", m)\n",
    "\n",
    "# Optional: restrict metrics (advanced users only)\n",
    "METRICS_TO_USE = [\n",
    "    # \"Weighted Mean Firing Rate (Hz)\",\n",
    "]\n",
    "\n",
    "METRICS = METRICS_TO_USE if METRICS_TO_USE else AVAILABLE_METRICS\n",
    "print(f\"\\nMetrics that will be plotted/exported ({len(METRICS)}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7dbb2-fe8f-4274-9164-c1cabd5eef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MASTER DF SANITY CHECKS\n",
    "# =========================\n",
    "\n",
    "print(\"\\nValue summary:\")\n",
    "display(master_df[\"value\"].describe())\n",
    "\n",
    "print(\"\\nMetric counts:\")\n",
    "display(master_df[\"metric\"].value_counts())\n",
    "\n",
    "print(\"\\nCondition counts:\")\n",
    "display(master_df[\"condition\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed1bd8-a7f7-4d54-8a1c-a3b9f76002f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREVIEW DATA\n",
    "# =========================\n",
    "\n",
    "display(master_df.head(10)) # <-- Change the number to the desired number of rows to show, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de264e1-8ec3-45a8-9c60-3406803f8702",
   "metadata": {},
   "source": [
    "## Part 4: QC & Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e146506-2563-41cf-af89-d7da8a50da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OUTLIER DETECTION SETUP\n",
    "# =========================\n",
    "\n",
    "outlier_spec = OutlierSpec(\n",
    "    method=OUTLIER_METHOD,\n",
    "    threshold=OUTLIER_Z,\n",
    "    group_cols=(\"plate_id\", \"metric\", \"time_point\", \"condition\"),\n",
    "    value_col=\"value\"\n",
    ")\n",
    "\n",
    "print(\"Outlier detection spec:\")\n",
    "print(outlier_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b76504-7fa6-461d-b536-fd6b8f0be915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FLAG OUTLIERS (NON-DESTRUCTIVE)\n",
    "# =========================\n",
    "\n",
    "df_flagged = flag_outliers(\n",
    "    master_df,\n",
    "    spec=outlier_spec\n",
    ")\n",
    "\n",
    "print(\"Outlier flagging completed.\")\n",
    "print(\"Total flagged outliers:\", df_flagged[\"is_outlier\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf2c1a-7e4a-425c-b4bd-4dcce3bd435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OUTLIERS TABLE\n",
    "# =========================\n",
    "\n",
    "outliers_table = get_outliers_table(df_flagged)\n",
    "\n",
    "print(\"Number of outliers detected:\", len(outliers_table))\n",
    "display(outliers_table.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8ab81-0726-4cef-81df-37b4d17ca1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RAW DATA QC PLOT (WITH OUTLIERS)\n",
    "# =========================\n",
    "\n",
    "for metric in METRICS:\n",
    "    print(f\"QC plot (raw data): {metric}\")\n",
    "\n",
    "    fig = plot_metric_timecourse(\n",
    "        df_flagged,\n",
    "        metric=metric\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2a123-f462-44d0-bee8-1a14c79bf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# APPLY OUTLIER FILTER (OPTIONAL)\n",
    "# =========================\n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_filtered = apply_outlier_filter(df_flagged)\n",
    "    print(\"Outliers removed (values set to NaN).\")\n",
    "    print(\"NaNs after filtering:\", df_filtered[\"value\"].isna().sum())\n",
    "else:\n",
    "    df_filtered = df_flagged.copy()\n",
    "    print(\"Outliers retained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38094dda-64a0-45bd-88b7-7a7630c7ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SAVE QC TABLES\n",
    "# =========================\n",
    "\n",
    "qc_flagged_path = OUTPUTS_DIR / \"master_flagged_long.csv\"\n",
    "qc_filtered_path = OUTPUTS_DIR / \"master_filtered_long.csv\"\n",
    "\n",
    "df_flagged.to_csv(qc_flagged_path, index=False)\n",
    "df_filtered.to_csv(qc_filtered_path, index=False)\n",
    "\n",
    "print(\"QC tables saved:\")\n",
    "print(\" -\", qc_flagged_path)\n",
    "print(\" -\", qc_filtered_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed691c-dabd-4761-a040-25ad49ccdd37",
   "metadata": {},
   "source": [
    "## Part 5: Baseline normalization\n",
    "\n",
    "- Values are normalized to the baseline (time point 0) on a per-well basis:\n",
    "\n",
    "- Normalized value = Value / Baseline Value\n",
    "\n",
    "- Wells with missing or zero baseline values are excluded from normalization, because division would be undefined or biologically meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81504a-c26f-4fb3-b1e6-838707d31412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BASELINE NORMALIZATION\n",
    "# =========================\n",
    "\n",
    "if NORMALIZE_TO_BASELINE:\n",
    "    df_norm, baseline_qc = baseline_normalize(\n",
    "    df_filtered,\n",
    "    baseline_time_point=0,\n",
    "    value_col=\"value\",\n",
    "    normalized_col=\"value_norm\",\n",
    "    method=\"ratio\",                 # ratio is usually the cleanest (baseline=1)\n",
    "    exclude_zero_baseline=True,\n",
    "    keep_excluded_rows=False,\n",
    "    return_qc_table=True\n",
    ")\n",
    "\n",
    "    print(\"Baseline normalization completed.\")\n",
    "    print(\"Wells excluded due to baseline issues:\", baseline_qc.shape[0])\n",
    "else:\n",
    "    df_norm = df_filtered.copy()\n",
    "    print(\"Baseline normalization skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae73c41-3ba4-4f01-9c0a-1b0ab766e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BASELINE QC TABLE\n",
    "# =========================\n",
    "\n",
    "if NORMALIZE_TO_BASELINE:\n",
    "    print(\"Baseline exclusion reasons:\")\n",
    "    display(baseline_qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a07c0-bf3e-4b46-aa75-c7c701f4170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# NORMALIZED TIMECOURSE PLOT\n",
    "# =========================\n",
    "\n",
    "if NORMALIZE_TO_BASELINE:\n",
    "    for metric in METRICS:\n",
    "        print(f\"Normalized timecourse: {metric}\")\n",
    "\n",
    "        fig = plot_metric_timecourse(\n",
    "            df_norm,\n",
    "            metric=metric,\n",
    "            value_col=\"value_norm\"\n",
    "        )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0552a-8cb7-4dd1-b110-f699744d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SAVE NORMALIZED MASTER TABLE\n",
    "# =========================\n",
    "\n",
    "if NORMALIZE_TO_BASELINE:\n",
    "    norm_master_path = OUTPUTS_DIR / \"master_normalized_long.csv\"\n",
    "    df_norm.to_csv(norm_master_path, index=False)\n",
    "    print(\"Normalized master table saved to:\")\n",
    "    print(norm_master_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672c5fc-02d0-4e7b-b08b-be8c1235c5d4",
   "metadata": {},
   "source": [
    "## Part 6: Statistics (Comparisons within timepoint)\n",
    "\n",
    "### The next cell should be edited by users to set statistics options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7b08-580e-4fe5-bbf3-37de57541206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STATISTICS OPTIONS\n",
    "# =========================\n",
    "\n",
    "# Which data to use for statistics\n",
    "STATS_MODE = \"normalized\"            # <-- CHANGE THIS TO YOUR CHOICE \"raw\" or \"normalized\"\n",
    "\n",
    "# Statistical test family\n",
    "STATS_TEST_FAMILY = \"nonparametric\"  # <-- CHANGE THIS TO YOUR CHOICE \"parametric\" or \"nonparametric\"\n",
    "\n",
    "# Multiple testing correction\n",
    "P_ADJUST_METHOD = \"fdr_bh\"           # <-- CHANGE THIS TO YOUR CHOICE \"bonferroni\", \"holm\", \"fdr_bh\"\n",
    "\n",
    "# Minimum number of wells per condition\n",
    "MIN_N_PER_GROUP = 3                  # <-- CHANGE THIS TO YOUR CHOICE (Minimum of 3 wells recommended)\n",
    "\n",
    "print(\"STATS_MODE:\", STATS_MODE)\n",
    "print(\"STATS_TEST_FAMILY:\", STATS_TEST_FAMILY)\n",
    "print(\"P_ADJUST_METHOD:\", P_ADJUST_METHOD)\n",
    "print(\"MIN_N_PER_GROUP:\", MIN_N_PER_GROUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2718504-7455-4664-bc72-dda8bd3e5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SELECT DATA FOR STATS\n",
    "# =========================\n",
    "\n",
    "if STATS_MODE == \"normalized\":\n",
    "    if \"value_norm\" not in df_norm.columns:\n",
    "        raise ValueError(\"Normalized data requested but df_norm is missing.\")\n",
    "    stats_df = df_norm\n",
    "    VALUE_COL = \"value_norm\"\n",
    "else:\n",
    "    stats_df = df_filtered\n",
    "    VALUE_COL = \"value\"\n",
    "\n",
    "print(\"Using value column:\", VALUE_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c21b5-c957-4522-a332-e7e5a6034dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# INITIALIZE STATS SPEC\n",
    "# =========================\n",
    "\n",
    "from statistics.timepoint_tests import (\n",
    "    TimepointStatsSpec,\n",
    "    compare_conditions_at_timepoint\n",
    ")\n",
    "\n",
    "stats_spec = TimepointStatsSpec(\n",
    "    test_family=STATS_TEST_FAMILY,\n",
    "    p_adjust_method=P_ADJUST_METHOD,\n",
    "    value_col=VALUE_COL\n",
    ")\n",
    "\n",
    "print(stats_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767e553-19be-4924-87d2-29fe60bcb6e7",
   "metadata": {},
   "source": [
    "### Here you can quickly run statistics on one metric at a single time point (optional)\n",
    "\n",
    "Replace \"Weighted Mean Firing Rate (Hz)\" for the desired available metric\n",
    "\n",
    "Select one time point to analyze based on files index (1_, 2_, etc), cannot be the baseline\n",
    "\n",
    "### List of available metrics:\n",
    "\n",
    "Count:\n",
    "- Number of Active Electrodes\n",
    "- Number of Bursts\n",
    "- Number of Network Bursts\n",
    "\n",
    "Rate:\n",
    "- Weighted Mean Firing Rate (Hz)\n",
    "- Burst Frequency - Avg (Hz)\n",
    "- Network Burst Frequency - Avg (Hz)\n",
    "\n",
    "Duration:\n",
    "- Burst Duration - Avg (sec)\n",
    "- Network Burst Duration - Avg (sec)\n",
    "- Network IBI Coefficient of Variation\n",
    "\n",
    "Other:\n",
    "- Synchrony Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675e3ef-d8db-4b45-86fc-2f9ef9d26309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RUN STATS: SINGLE TIME POINT (EXPLORATORY)\n",
    "# =========================\n",
    "\n",
    "METRIC_STATS = \"Weighted Mean Firing Rate (Hz)\"  # user selects ONE metric\n",
    "TIME_POINT = 3                                   # user selects ONE timepoint\n",
    "\n",
    "desc_df, omnibus_df, pairwise_df = compare_conditions_at_timepoint(\n",
    "    stats_df,\n",
    "    metric=METRIC_STATS,\n",
    "    time_point=TIME_POINT,\n",
    "    spec=stats_spec,\n",
    "    min_n_per_group=MIN_N_PER_GROUP\n",
    ")\n",
    "\n",
    "print(f\"Statistics for metric: {METRIC_STATS} at time point {TIME_POINT}\")\n",
    "\n",
    "print(\"Descriptive statistics:\")\n",
    "display(desc_df)\n",
    "\n",
    "print(\"Omnibus test:\")\n",
    "display(omnibus_df)\n",
    "\n",
    "print(\"Pairwise comparisons:\")\n",
    "display(pairwise_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a42a61-ee2e-415e-b1cd-b5d7a76b843a",
   "metadata": {},
   "source": [
    "### No alterations are needed in the rest of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2485d-8f40-48f5-94da-657ad4288951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RUN STATS ACROSS TIME POINTS\n",
    "# =========================\n",
    "\n",
    "all_timepoints = sorted(stats_df[\"time_point\"].unique())\n",
    "\n",
    "all_desc = []\n",
    "all_omnibus = []\n",
    "all_pairwise = []\n",
    "\n",
    "for metric in METRICS:\n",
    "    print(f\"Running stats for metric: {metric}\")\n",
    "\n",
    "    if metric not in stats_df[\"metric\"].unique():\n",
    "        print(f\"⚠ Metric not found in stats_df: {metric}\")\n",
    "        continue\n",
    "\n",
    "    for tp in all_timepoints:\n",
    "        try:\n",
    "            d, o, p = compare_conditions_at_timepoint(\n",
    "                stats_df,\n",
    "                metric=metric,\n",
    "                time_point=int(tp),\n",
    "                spec=stats_spec,\n",
    "                min_n_per_group=MIN_N_PER_GROUP\n",
    "            )\n",
    "\n",
    "            all_desc.append(d.assign(metric=metric, time_point=tp))\n",
    "            all_omnibus.append(o.assign(metric=metric, time_point=tp))\n",
    "            all_pairwise.append(p.assign(metric=metric, time_point=tp))\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping metric={metric}, time point={tp}: {e}\")\n",
    "\n",
    "# Concatenate only if something was computed\n",
    "if all_desc:\n",
    "    desc_all_tp = pd.concat(all_desc, ignore_index=True)\n",
    "    omnibus_all_tp = pd.concat(all_omnibus, ignore_index=True)\n",
    "    pairwise_all_tp = pd.concat(all_pairwise, ignore_index=True)\n",
    "\n",
    "    print(\"✓ Statistics computed across metrics and time points.\")\n",
    "else:\n",
    "    print(\"⚠ No statistics computed — check metrics, groups, or sample size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66087c3-1e65-4d49-9b23-1a9fcf9db0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# INSPECT AND SAVE STATISTICS TABLES\n",
    "# =========================\n",
    "\n",
    "desc_path = OUTPUTS_DIR / \"stats_descriptives_all_metrics.csv\"\n",
    "omnibus_path = OUTPUTS_DIR / \"stats_omnibus_all_metrics.csv\"\n",
    "pairwise_path = OUTPUTS_DIR / \"stats_pairwise_all_metrics.csv\"\n",
    "\n",
    "desc_all_tp.to_csv(desc_path, index=False)\n",
    "omnibus_all_tp.to_csv(omnibus_path, index=False)\n",
    "pairwise_all_tp.to_csv(pairwise_path, index=False)\n",
    "\n",
    "print(\"Statistics tables saved:\")\n",
    "print(\" -\", desc_path)\n",
    "print(\" -\", omnibus_path)\n",
    "print(\" -\", pairwise_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746aed1-5f2d-4328-8aed-dc45a32f41ff",
   "metadata": {},
   "source": [
    "## Part 7: Exports & Final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a2ef9-6102-4eb4-90ea-9c8bdc1fcf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EXPORT CLEAN TABLES (PRISM-FRIENDLY)\n",
    "# =========================\n",
    "\n",
    "exported_dirs = []\n",
    "processed_dir = PROCESSED_DIR  # already defined earlier as PROJECT_ROOT/data/processed\n",
    "\n",
    "if EXPORT_MODE in (\"raw\", \"both\"):\n",
    "    raw_dir = export_metric_tables_wide(\n",
    "        master_df,\n",
    "        out_dir=processed_dir,\n",
    "        config_handler=config_handler,\n",
    "        mode=\"raw\",\n",
    "        timepoint_labels=timepoint_labels,\n",
    "        drop_unassigned_wells=True\n",
    "    )\n",
    "    exported_dirs.append(raw_dir)\n",
    "\n",
    "if EXPORT_MODE in (\"normalized\", \"both\"):\n",
    "    if \"value_norm\" not in df_norm.columns:\n",
    "        print(\"⚠ Normalized export requested, but normalization was not performed.\")\n",
    "    else:\n",
    "        norm_dir = export_metric_tables_wide(\n",
    "            df_norm,\n",
    "            out_dir=processed_dir,\n",
    "            config_handler=config_handler,\n",
    "            mode=\"normalized\",\n",
    "            timepoint_labels=timepoint_labels,\n",
    "            drop_unassigned_wells=True\n",
    "        )\n",
    "        exported_dirs.append(norm_dir)\n",
    "\n",
    "print(\"Export complete. Tables written to:\")\n",
    "for d in exported_dirs:\n",
    "    print(\" -\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74615efb-1ec1-41d4-bf08-9f6b54004033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EXPORT FIGURES FOR SELECTED METRICS\n",
    "# =========================\n",
    "\n",
    "for metric in METRICS:\n",
    "    print(f\"Exporting figures for: {metric}\")\n",
    "\n",
    "    safe_metric = metric.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "\n",
    "    # RAW plot (post outlier handling)\n",
    "    fig_raw = plot_metric_timecourse(\n",
    "        df_filtered,\n",
    "        metric=metric,\n",
    "        use_normalized=False,\n",
    "        show_outliers=False,\n",
    "        timepoint_labels=timepoint_labels,\n",
    "        show=False          # <-- THIS is the key change\n",
    "    )\n",
    "    raw_fig_path = FIGURES_DIR / f\"RAW_{safe_metric}.png\"\n",
    "    fig_raw.savefig(raw_fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig_raw)\n",
    "    print(\"Saved:\", raw_fig_path)\n",
    "\n",
    "    # NORMALIZED plot (if available)\n",
    "    if \"value_norm\" in df_norm.columns:\n",
    "        fig_norm = plot_metric_timecourse(\n",
    "            df_norm,\n",
    "            metric=metric,\n",
    "            use_normalized=True,\n",
    "            show_outliers=False,\n",
    "            timepoint_labels=timepoint_labels,\n",
    "            show=False      # <-- AND THIS\n",
    "        )\n",
    "        norm_fig_path = FIGURES_DIR / f\"NORM_{safe_metric}.png\"\n",
    "        fig_norm.savefig(norm_fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig_norm)\n",
    "        print(\"Saved:\", norm_fig_path)\n",
    "    else:\n",
    "        print(\"Normalization not performed → normalized figure not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1be976-6247-40c9-9ea9-8dd5198f54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EXPORT MASTER TABLES (LONG FORMAT)\n",
    "# =========================\n",
    "\n",
    "master_df.to_csv(OUTPUTS_DIR / \"master_raw_long.csv\", index=False)\n",
    "df_flagged.to_csv(OUTPUTS_DIR / \"master_flagged_long.csv\", index=False)\n",
    "df_filtered.to_csv(OUTPUTS_DIR / \"master_filtered_long.csv\", index=False)\n",
    "\n",
    "if \"value_norm\" in df_norm.columns:\n",
    "    df_norm.to_csv(OUTPUTS_DIR / \"master_normalized_long.csv\", index=False)\n",
    "\n",
    "print(\"Master tables exported to:\", OUTPUTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da074e-22f9-4dcc-b704-60e8a11423e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FINAL RUN SUMMARY\n",
    "# =========================\n",
    "\n",
    "plate_id = experiment_info.get(\"plate_id\", \"UNKNOWN\")\n",
    "n_files = len(csv_files)\n",
    "n_metrics = master_df[\"metric\"].nunique()\n",
    "n_timepoints = master_df[\"time_point\"].nunique()\n",
    "n_assigned_rows = master_df[\"condition\"].notna().sum()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MEA ANALYSIS RUN SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Plate ID:\", plate_id)\n",
    "print(\"CSV files processed:\", n_files)\n",
    "print(\"Time points:\", n_timepoints)\n",
    "print(\"Metrics detected:\", n_metrics)\n",
    "print(\"Rows (assigned wells only):\", n_assigned_rows)\n",
    "\n",
    "# Outliers\n",
    "if \"is_outlier\" in df_flagged.columns:\n",
    "    print(\"Outliers flagged:\", int(df_flagged[\"is_outlier\"].sum()))\n",
    "else:\n",
    "    print(\"Outliers flagged: (no outlier column found)\")\n",
    "\n",
    "# Baseline exclusions\n",
    "if NORMALIZE_TO_BASELINE and \"baseline_qc\" in globals():\n",
    "    print(\"Wells excluded due to baseline issues:\", len(baseline_qc))\n",
    "else:\n",
    "    print(\"Baseline exclusion table: not generated\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "print(\" - Long tables:\", OUTPUTS_DIR)\n",
    "print(\" - Figures:\", FIGURES_DIR)\n",
    "print(\" - Prism tables:\", PROCESSED_DIR)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Done.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
